{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3c947b6-ec03-4e21-9bcb-b190fce4b42b",
   "metadata": {},
   "source": [
    "## Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "066ac74b-4996-4f89-8464-23899701be98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe45b09a-f996-4621-bb14-d1d3c4e84ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vijay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\vijay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80ddaf7-db86-4635-8f8c-f921052c7b08",
   "metadata": {},
   "source": [
    "#### Checking if CUDA is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70856f36-e66e-4883-8715-c777f6cc4c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec3b6f9-ed2f-4091-8eaa-70b35a8e9258",
   "metadata": {},
   "source": [
    "## Example Song (Input - Document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "986ea77f-da7e-4c48-9bf1-77d4cf5a54f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "song= \"\"\"We are no strangers to love\n",
    "You know the rules and so do I\n",
    "A full commitments what Im thinking of\n",
    "You wouldnt get this from any other guy\n",
    "I just wanna tell you how Im feeling\n",
    "Gotta make you understand\n",
    "Never gonna give you up\n",
    "Never gonna let you down\n",
    "Never gonna run around and desert you\n",
    "Never gonna make you cry\n",
    "Never gonna say goodbye\n",
    "Never gonna tell a lie and hurt you\n",
    "Weve known each other for so long\n",
    "Your hearts been aching but youre too shy to say it\n",
    "Inside we both know whats been going on\n",
    "We know the game and were gonna play it\n",
    "And if you ask me how Im feeling\n",
    "Dont tell me youre too blind to see\n",
    "Never gonna give you up\n",
    "Never gonna let you down\n",
    "Never gonna run around and desert you\n",
    "Never gonna make you cry\n",
    "Never gonna say goodbye\n",
    "Never gonna tell a lie and hurt you\n",
    "Never gonna give you up\n",
    "Never gonna let you down\n",
    "Never gonna run around and desert you\n",
    "Never gonna make you cry\n",
    "Never gonna say goodbye\n",
    "Never gonna tell a lie and hurt you\n",
    "Weve known each other for so long\n",
    "Your hearts been aching but youre too shy to say it\n",
    "Inside we both know whats been going on\n",
    "We know the game and were gonna play it\n",
    "I just wanna tell you how Im feeling\n",
    "Gotta make you understand\n",
    "Never gonna give you up\n",
    "Never gonna let you down\n",
    "Never gonna run around and desert you\n",
    "Never gonna make you cry\n",
    "Never gonna say goodbye\n",
    "Never gonna tell a lie and hurt you\n",
    "Never gonna give you up\n",
    "Never gonna let you down\n",
    "Never gonna run around and desert you\n",
    "Never gonna make you cry\n",
    "Never gonna say goodbye\n",
    "Never gonna tell a lie and hurt you\n",
    "Never gonna give you up\n",
    "Never gonna let you down\n",
    "Never gonna run around and desert you\n",
    "Never gonna make you cry\n",
    "Never gonna say goodbye\n",
    "Never gonna tell a lie and hurt you\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb0f80c-3046-476f-a74f-7832dae685a9",
   "metadata": {},
   "source": [
    "## Bigram language model - Using Conditional Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c5c573-fb85-407c-89a3-194ca26ac20a",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08bed078-43d6-4f29-9344-110ccc27e4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Input Word:- 'Word2Vec'\n",
      "Example Output Word:- WordVec\n"
     ]
    }
   ],
   "source": [
    "# a function to remove all not-word characters in a word\n",
    "def preprocess_string(s):\n",
    "    # remove all non-word charecters except numbers and letters\n",
    "    s = re.sub(r\"[^\\w\\s]\",'',s)\n",
    "    # replace all runs of witespaces with no space\n",
    "    s = re.sub(r\"\\s+\",'',s)\n",
    "    # replace digits with no space\n",
    "    s = re.sub(r\"\\d\",'',s)\n",
    "    return s\n",
    "\n",
    "print(f\"Example Input Word:- 'Word2Vec'\\nExample Output Word:- {preprocess_string('Word2Vec')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "815342b6-8f1e-4a46-bb56-8edbb248870d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1st ten tokens:-\n",
      "['we', 'are', 'no', 'strangers', 'to', 'love', 'you', 'know', 'the', 'rules']\n",
      "Total no of tokens :-385\n",
      "Total no of unique tokens :-80\n"
     ]
    }
   ],
   "source": [
    "# using the \"word_tokenize\" function from \"nltk\" library for tokenization\n",
    "def preprocess(words):\n",
    "    tokens = word_tokenize(words)\n",
    "    tokens = [preprocess_string(w) for w in tokens]\n",
    "    return [w.lower() for w in tokens if len(w) != 0 or not(w in string.punctuation)]\n",
    "\n",
    "tokens=preprocess(song) # preserves the order\n",
    "vocabulary = set(tokens)\n",
    "print(f\"Example 1st ten tokens:-\\n{tokens[0:10]}\")\n",
    "print(f'Total no of tokens :-{len(tokens)}')\n",
    "print(f'Total no of unique tokens :-{len(vocabulary)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aac3553-2339-4acc-8ba5-0bd872f8b423",
   "metadata": {},
   "source": [
    "#### Calcualting the frequency distribution of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaa7e3dd-2377-47e0-a6f1-bbbbe811d4de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'na': 40, 'gon': 38, 'you': 37, 'never': 36, 'and': 16, 'tell': 9, 'make': 8, 'say': 8, 'a': 7, 'give': 6, ...})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total word count:- 385\n",
      "Total unique word count:- 80 \n"
     ]
    }
   ],
   "source": [
    "# using the \"FreqDist\" function from \"nltk\" library to calculate the token frequecy\n",
    "fdist = nltk.FreqDist(tokens)\n",
    "display(fdist)\n",
    "\n",
    "# total counts\n",
    "print(f\"Total word count:- {sum(fdist.values())}\")\n",
    "print(f\"Total unique word count:- {len(list(fdist.keys()))} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "875f68ed-79c3-4372-b965-84ca6cb6652e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# a bar plot with the first ten token frequencies using the \"pyplot\" function from \"matplotlib\" library\n",
    "plt.bar(list(fdist.keys())[0:10], list(fdist.values())[0:10])\n",
    "plt.xlabel(\"Words\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec57d961-1126-481d-a477-84ba5a1f117a",
   "metadata": {},
   "source": [
    "#### Creating bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8628a95b-2b25-41dc-bbdd-a1e68e138929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first ten bigrmas:-\n",
      "[('we', 'are'), ('are', 'no'), ('no', 'strangers'), ('strangers', 'to'), ('to', 'love'), ('love', 'you'), ('you', 'know'), ('know', 'the'), ('the', 'rules'), ('rules', 'and')]\n"
     ]
    }
   ],
   "source": [
    "# creating consecutive pairs of tokens using the \"bigrams\" function from \"nltk\" library\n",
    "bigrams = list(nltk.bigrams(tokens))\n",
    "print(f'The first ten bigrmas:-\\n{bigrams[:10]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00943c82-1843-4fb6-a554-935ae93da3c9",
   "metadata": {},
   "source": [
    "#### Calcutating the frequency distribution of bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96970538-e5ba-43e9-ad57-943c15763a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('gon', 'na'): 38, ('never', 'gon'): 36, ('you', 'never'): 9, ('na', 'tell'): 8, ('make', 'you'): 8, ('na', 'give'): 6, ('give', 'you'): 6, ('you', 'up'): 6, ('up', 'never'): 6, ('na', 'let'): 6, ...})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total bigram count:- 384\n",
      "Total unique bigram count:- 119 \n"
     ]
    }
   ],
   "source": [
    "# using the \"FreqDist\" function from \"nltk\" library to calculate the bigram frequecy\n",
    "freq_bigrams = nltk.FreqDist(nltk.bigrams(tokens))\n",
    "display(freq_bigrams)\n",
    "\n",
    "# total counts\n",
    "print(f\"Total bigram count:- {sum(freq_bigrams.values())}\")\n",
    "print(f\"Total unique bigram count:- {len(list(freq_bigrams.keys()))} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cd8f4b-b8a8-4990-99b5-7d97a3cd746d",
   "metadata": {},
   "source": [
    "#### Calculating the conditional probabilities for the example token - \"strangers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7774f6ad-9b6b-4df4-a60a-0c7956a454d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 4 more likely word to occur after 'strangers':-\n",
      " [('to', 1.0), ('we', 0.0), ('whats', 0.0), ('im', 0.0)]\n"
     ]
    }
   ],
   "source": [
    "word = 'strangers'\n",
    "vocab_probabilities = {}\n",
    "for next_word in vocabulary:\n",
    "    vocab_probabilities[next_word] = freq_bigrams[(word, next_word)]/fdist[word]\n",
    "\n",
    "vocab_probabilities = sorted(vocab_probabilities.items(), key=lambda x:x[1], reverse=True)\n",
    "\n",
    "print(\"Top 4 more likely word to occur after 'strangers':-\\n\", vocab_probabilities[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859290ca-8942-4119-bcf7-0d9cc0c0c5dd",
   "metadata": {},
   "source": [
    "#### A function for next word prediction using conditional probability of the next word given a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9a5932d-28cc-422d-9b0a-85501fad6f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 4 more likely word to occur after 'strangers':-\n",
      " [('to', 1.0), ('we', 0.0), ('whats', 0.0), ('im', 0.0)]\n"
     ]
    }
   ],
   "source": [
    "def make_predictions(input_context_words, freq_grams, norm,vocabulary=vocabulary):\n",
    "    vocab_probabilities = {}\n",
    "    input_context_tokens = preprocess(input_context_words)\n",
    "\n",
    "    # calculating the probabilities\n",
    "    for next_word in vocabulary:\n",
    "        temp = input_context_tokens.copy()\n",
    "        temp.append(next_word) # adding the next word to the context\n",
    "\n",
    "        #calculating the conditional probability\n",
    "        vocab_probabilities[next_word] = freq_grams[tuple(temp)] / norm\n",
    "\n",
    "    # sorting the probabilities\n",
    "    vocab_probabilities = sorted(vocab_probabilities.items(), key=lambda x:x[1], reverse=True)\n",
    "\n",
    "    return vocab_probabilities\n",
    "\n",
    "print(\"Top 4 more likely word to occur after 'strangers':-\\n\", make_predictions('strangers', freq_bigrams, fdist['strangers'])[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f558c21b-beb2-4597-85e7-e91fe5cb193e",
   "metadata": {},
   "source": [
    "#### Generating a song using the bigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d928ebd-5e06-4e16-be4d-58329f064c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we both know the game and hurt you never gon na tell a lie and hurt you never gon na tell a lie and hurt you never gon na tell a lie and hurt you never gon na tell a lie and hurt you never gon na tell a lie and hurt you never gon na tell a lie and hurt you never gon na tell a lie and hurt you never gon na tell a lie and hurt you never gon na tell a lie and hurt you never gon na tell a lie and hurt you never gon na\n"
     ]
    }
   ],
   "source": [
    "my_song=\"we\"\n",
    "input_word = my_song\n",
    "for i in range(100):\n",
    "    next_word = make_predictions(input_word, freq_bigrams, fdist[input_word])[0][0]\n",
    "    my_song += \" \"+ next_word\n",
    "    input_word = next_word\n",
    "\n",
    "print(my_song)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1a0820-8e96-49db-9674-dab4d997ae8a",
   "metadata": {},
   "source": [
    "## Language Models - Using Feedforward Neural Networks (FNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40791081-9b30-493d-ae56-704873c0c5c8",
   "metadata": {},
   "source": [
    "#### Tokenization and building the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37c6eb42-556e-46e1-9737-c87fd6740d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of tokens in the song:-  343\n",
      "Vocab Size:- 79\n",
      "\n",
      "First 10 word of the song:-\n",
      " We are no strangers to love You know the rules \n",
      "\n",
      "Tokenized text:-\n",
      " ['we', 'are', 'no', 'strangers', 'to', 'love', 'you', 'know', 'the', 'rules'] \n",
      "\n",
      "Token indices:-\n",
      " [21, 58, 70, 74, 25, 69, 2, 20, 31, 72]\n"
     ]
    }
   ],
   "source": [
    "# using the \"get_tokenizer\" function from \"torchtext\" library for tokenization\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "tokens = tokenizer(song)\n",
    "print('No of tokens in the song:- ',len(tokens))\n",
    "\n",
    "# an iterable to generate the vocabulary\n",
    "tokenized_song = map(tokenizer, song.split())\n",
    "\n",
    "# using the 'buid_vocab_from_iterator' function from 'torchtext' library\n",
    "vocab = build_vocab_from_iterator(tokenized_song, specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab['<unk>']) # # This index will be returned when OOV token is queried\n",
    "vocab_size = len(vocab)\n",
    "print(f\"Vocab Size:- {vocab_size}\\n\")\n",
    "\n",
    "# printing the tokenized text and token indices of 1st 10 words of the song\n",
    "song_first_10 = \" \".join(song.split()[:10])\n",
    "tokenized_text = tokenizer(song_first_10)\n",
    "token_indices = vocab(tokenized_text)\n",
    "print(\"First 10 word of the song:-\\n\",song_first_10,\"\\n\")\n",
    "print(\"Tokenized text:-\\n\",tokenized_text,\"\\n\")\n",
    "print(\"Token indices:-\\n\", token_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805c2d9c-8ea6-4b59-a34b-477c12e748e2",
   "metadata": {},
   "source": [
    "#### Creating n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "529196d4-b629-4510-94bc-240146004153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([context words list], target-word)\n",
      "\n",
      "([t-1,t-2,t-3]) t\n",
      "\n",
      "(['no', 'are', 'we'], 'strangers')\n",
      "(['strangers', 'no', 'are'], 'to')\n",
      "(['to', 'strangers', 'no'], 'love')\n",
      "(['love', 'to', 'strangers'], 'you')\n",
      "(['you', 'love', 'to'], 'know')\n"
     ]
    }
   ],
   "source": [
    "CONTEXT_SIZE = 3\n",
    "ngrams = [\n",
    "    ([tokens[i-j-1] for j in range(CONTEXT_SIZE)], tokens[i])\n",
    "    for i in range(CONTEXT_SIZE, len(tokens))\n",
    "]\n",
    "\n",
    "# printing the first 5 ngram\n",
    "print(\"([context words list], target-word)\\n\")\n",
    "print(\"([t-1,t-2,t-3]) t\\n\")\n",
    "for ngram in ngrams[:5]: print(ngram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133b8043-dd5c-448b-87c0-c143445afc83",
   "metadata": {},
   "source": [
    "#### Pre-processing pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7dde21cd-a9c1-44ba-8fff-e1059d44fdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipline to convert raw text into token indices using the \"tokenizer\" and \"vocab\" functions defined about\n",
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "\n",
    "# a pipline to get token given token index\n",
    "index_to_token_pipeline = lambda x: vocab.get_itos()[x]\n",
    "\n",
    "\n",
    "CONTEXT_SIZE=3\n",
    "BATCH_SIZE=10\n",
    "EMBEDDING_DIM = 10\n",
    "\n",
    "# the collate function to process the batches from the dataloaders\n",
    "def collate_batch(batch):\n",
    "    batch_size = len(batch)\n",
    "    context, target = [], []\n",
    "    for i in range(CONTEXT_SIZE, batch_size):\n",
    "        target.append(vocab([batch[i]]))\n",
    "        context.append(vocab([batch[i-j-1] for j in range(CONTEXT_SIZE)]))\n",
    "    return torch.tensor(context).to(device), torch.tensor(target).to(device).reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f8c4c4-16a8-406a-a1d2-3be387bd9b87",
   "metadata": {},
   "source": [
    "#### Creating dataloaders for ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "310b5ea4-e1fa-4b0d-b9af-d5bb21cd6777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data in the first batch:- \n",
      "\n",
      "Contect Words:- [no, are, we]             Target Word:- strangers\n",
      "Contect Words:- [strangers, no, are]      Target Word:- to\n",
      "Contect Words:- [to, strangers, no]       Target Word:- love\n",
      "Contect Words:- [love, to, strangers]     Target Word:- you\n",
      "Contect Words:- [you, love, to]           Target Word:- know\n",
      "Contect Words:- [know, you, love]         Target Word:- the\n",
      "Contect Words:- [the, know, you]          Target Word:- rules\n",
      "\n",
      "Context tensors:- \n",
      " tensor([[70, 58, 21],\n",
      "        [74, 70, 58],\n",
      "        [25, 74, 70],\n",
      "        [69, 25, 74],\n",
      "        [ 2, 69, 25],\n",
      "        [20,  2, 69],\n",
      "        [31, 20,  2]], device='cuda:0')\n",
      "\n",
      "Target tensor:- \n",
      " tensor([74, 25, 69,  2, 20, 31, 72], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 10\n",
    "padding = BATCH_SIZE - len(tokens)%BATCH_SIZE # appending the beginning of the song to the end to get unifrom batches\n",
    "tokens_paded = tokens + tokens[:padding]\n",
    "\n",
    "# creating dataloaders using \"DataLoader\" function from \"pytorch\" library\n",
    "dataloader = DataLoader(\n",
    "    tokens_paded,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_batch\n",
    ")\n",
    "\n",
    "#printing the data in the first batch\n",
    "print(\"The data in the first batch:- \\n\")\n",
    "context_tensors, target_tensors = next(iter(dataloader))\n",
    "for context_tensor, target_tensor in zip(context_tensors, target_tensors):\n",
    "    context_words = [index_to_token_pipeline(t) for t in context_tensor]\n",
    "    target_word = index_to_token_pipeline(target_tensor)\n",
    "    print(\"Contect Words:- {:<25} Target Word:- {}\".format(\"[\"+\", \".join(context_words)+\"]\", target_word))\n",
    "print(\"\\nContext tensors:- \\n\", context_tensors)\n",
    "print(\"\\nTarget tensor:- \\n\", target_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f3a829-d1e4-4eaa-8d2c-f41ea2181dd2",
   "metadata": {},
   "source": [
    "#### Defining the Nural Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "10c75c5b-d165-4cd2-bf89-f83b1992cc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a feed forward NN implemented using \"nn.Embedding\", \"nn.Linear\" and \"nn.functional\" functions from \"pytorch\" library\n",
    "\n",
    "class NGramLanguageModeler(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        self.context_size = context_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size*embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(input) \n",
    "        embeds = torch.reshape(embeds, (-1, self.context_size*self.embedding_dim))\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "68827b98-7707-4f08-9b1b-6cf044e42e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating the model\n",
    "EMBEDDING_DIM = 10\n",
    "model = NGramLanguageModeler(vocab_size, EMBEDDING_DIM, CONTEXT_SIZE).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ca527c-6489-4bea-b43d-c2507a2beef2",
   "metadata": {},
   "source": [
    "#### Example of one forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6e04ebea-40bb-4bfa-865c-8e0590bc9f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example forwarf pass of the first n_gram:\n",
      "\n",
      "Contect Words:- [no, are, we]             Target Word:- strangers\n",
      "\n",
      "Context tensors:-\n",
      "tensor([[70, 58, 21], device='cuda:0')\n",
      "\n",
      "Context tensor embeddings:-\n",
      " tensor([[ 0.7307,  0.2689, -0.5523,  0.6353, -0.1539, -0.9658,  1.8148, -0.4063,\n",
      "          0.1848, -0.7447],\n",
      "        [-1.5605,  0.6927, -0.1327, -0.5621, -0.8637,  0.0152, -0.8167,  0.6541,\n",
      "          1.0358, -0.3060],\n",
      "        [-0.7393,  1.2424, -1.6711, -0.0937,  0.4314, -0.3739,  1.1067,  0.6083,\n",
      "          1.8445,  0.3956]], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "Re-shaped Context tensor embeddings:-\n",
      " tensor([ 0.7307,  0.2689, -0.5523,  0.6353, -0.1539, -0.9658,  1.8148, -0.4063,\n",
      "         0.1848, -0.7447, -1.5605,  0.6927, -0.1327, -0.5621, -0.8637,  0.0152,\n",
      "        -0.8167,  0.6541,  1.0358, -0.3060, -0.7393,  1.2424, -1.6711, -0.0937,\n",
      "         0.4314, -0.3739,  1.1067,  0.6083,  1.8445,  0.3956], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "\n",
      "Hidden layer output:-\n",
      " tensor([0.7802, 0.0000, 0.4760, 0.0000, 0.0000, 0.1019, 0.0000, 0.1661, 0.2237,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.8211, 0.0000, 0.3916, 0.4180, 0.0000,\n",
      "        0.0000, 0.6845, 0.0000, 0.7770, 0.0000, 0.0000, 0.7242, 0.0841, 0.1412,\n",
      "        0.0094, 0.0000, 0.4498, 0.2111, 0.0000, 0.0134, 0.1211, 0.3630, 0.0000,\n",
      "        0.0000, 0.5177, 0.8219, 0.0000, 0.2406, 0.0000, 0.0000, 0.4088, 0.0000,\n",
      "        0.0000, 0.7468, 0.5038, 0.0000, 0.7507, 0.0000, 0.6072, 0.0000, 0.2842,\n",
      "        0.0000, 0.0000, 0.0000, 0.1213, 1.3320, 0.2754, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.1382, 0.0000, 0.0000, 0.0015, 0.6788, 0.0000, 0.0000,\n",
      "        0.6307, 0.0902, 0.0000, 0.5597, 0.4273, 0.0000, 0.0000, 0.0000, 0.2805,\n",
      "        0.2612, 0.4490, 0.0000, 0.1735, 0.4581, 0.5328, 0.0000, 0.0000, 0.3410,\n",
      "        0.0000, 0.0000, 0.0000, 0.0880, 0.2153, 0.9134, 0.1396, 0.0000, 0.0000,\n",
      "        0.1656, 0.3544, 0.0000, 0.1968, 0.0000, 0.0000, 0.3699, 0.4016, 0.0000,\n",
      "        0.0000, 0.5430, 0.0000, 0.0072, 0.2191, 0.0000, 0.0000, 0.7724, 0.0000,\n",
      "        0.4796, 0.0000, 0.5493, 0.0000, 0.0000, 0.3377, 1.0766, 0.0799, 0.0000,\n",
      "        0.0889, 0.5752], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "Nural Network otuput:-\n",
      " tensor([ 0.0446, -0.1362,  0.1045, -0.2208,  0.2531, -0.0371,  0.0871, -0.4352,\n",
      "         0.0799,  0.2879,  0.1426,  0.0936, -0.0385,  0.1096, -0.0947,  0.3689,\n",
      "         0.1421,  0.0351,  0.2558,  0.3974, -0.0654,  0.0622, -0.2315,  0.1919,\n",
      "         0.5068, -0.1011, -0.0534, -0.1086,  0.1899,  0.2302, -0.1104,  0.2589,\n",
      "        -0.1393,  0.0417,  0.0029,  0.2409,  0.0408, -0.2188, -0.2025,  0.5288,\n",
      "        -0.0254, -0.2022, -0.2342,  0.1530,  0.2672,  0.2057,  0.0023,  0.0806,\n",
      "        -0.0419, -0.1147, -0.2601, -0.1400, -0.1556, -0.1678, -0.1613, -0.0801,\n",
      "         0.0477, -0.0050,  0.2479, -0.1228,  0.2109,  0.1014, -0.1128,  0.1258,\n",
      "        -0.0255,  0.0880,  0.0530,  0.0182, -0.3134, -0.3417,  0.1274,  0.1772,\n",
      "         0.0036, -0.2035, -0.5335,  0.1837,  0.1638,  0.2384, -0.4434],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# getting the embeddings of the context_tensors\n",
    "embedded_context_tensor = model.embeddings(context_tensors)\n",
    "# reshaping the context tensors to (EMBEDDING_DIM * CONTEXT_SIZE) dimention\n",
    "embedded_context_tensor_reshaped = torch.reshape(embedded_context_tensor, (-1,EMBEDDING_DIM * CONTEXT_SIZE))\n",
    "# passing through the first linear layer and relu activation function\n",
    "hidden_out = F.relu(model.linear1(embedded_context_tensor_reshaped))\n",
    "# final layer output\n",
    "nn_out = model.linear2(hidden_out)\n",
    "\n",
    "print(\"Example forward pass of the first n_gram:\\n\")\n",
    "print(\"Contect Words:- [no, are, we]             Target Word:- strangers\\n\")\n",
    "print(\"Context tensors:-\\ntensor([[70, 58, 21], device='cuda:0')\\n\")\n",
    "print(\"Context tensor embeddings:-\\n\",embedded_context_tensor[0])\n",
    "print(\"\\nRe-shaped Context tensor embeddings:-\\n\", embedded_context_tensor_reshaped[0])\n",
    "print(\"\\nHidden layer output:-\\n\", hidden_out[0])\n",
    "print(\"\\nNural Network otuput:-\\n\", nn_out[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2c0321ba-ccf9-4e10-bcb5-01fc9231c8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.8018e-01, 0.0000e+00, 4.7602e-01, 0.0000e+00, 0.0000e+00, 1.0192e-01,\n",
       "         0.0000e+00, 1.6611e-01, 2.2375e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 8.2112e-01, 0.0000e+00, 3.9158e-01, 4.1796e-01, 0.0000e+00,\n",
       "         0.0000e+00, 6.8455e-01, 0.0000e+00, 7.7695e-01, 0.0000e+00, 0.0000e+00,\n",
       "         7.2423e-01, 8.4070e-02, 1.4121e-01, 9.3730e-03, 0.0000e+00, 4.4978e-01,\n",
       "         2.1107e-01, 0.0000e+00, 1.3444e-02, 1.2113e-01, 3.6302e-01, 0.0000e+00,\n",
       "         0.0000e+00, 5.1771e-01, 8.2186e-01, 0.0000e+00, 2.4057e-01, 0.0000e+00,\n",
       "         0.0000e+00, 4.0876e-01, 0.0000e+00, 0.0000e+00, 7.4675e-01, 5.0383e-01,\n",
       "         0.0000e+00, 7.5067e-01, 0.0000e+00, 6.0721e-01, 0.0000e+00, 2.8418e-01,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2134e-01, 1.3320e+00, 2.7538e-01,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3817e-01,\n",
       "         0.0000e+00, 0.0000e+00, 1.5169e-03, 6.7883e-01, 0.0000e+00, 0.0000e+00,\n",
       "         6.3068e-01, 9.0207e-02, 0.0000e+00, 5.5975e-01, 4.2729e-01, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 2.8050e-01, 2.6124e-01, 4.4903e-01, 0.0000e+00,\n",
       "         1.7354e-01, 4.5808e-01, 5.3282e-01, 0.0000e+00, 0.0000e+00, 3.4105e-01,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 8.8039e-02, 2.1527e-01, 9.1336e-01,\n",
       "         1.3959e-01, 0.0000e+00, 0.0000e+00, 1.6555e-01, 3.5440e-01, 0.0000e+00,\n",
       "         1.9681e-01, 0.0000e+00, 0.0000e+00, 3.6992e-01, 4.0163e-01, 0.0000e+00,\n",
       "         0.0000e+00, 5.4305e-01, 0.0000e+00, 7.2371e-03, 2.1912e-01, 0.0000e+00,\n",
       "         0.0000e+00, 7.7235e-01, 0.0000e+00, 4.7962e-01, 0.0000e+00, 5.4934e-01,\n",
       "         0.0000e+00, 0.0000e+00, 3.3772e-01, 1.0766e+00, 7.9881e-02, 0.0000e+00,\n",
       "         8.8876e-02, 5.7518e-01],\n",
       "        [7.7122e-01, 1.2867e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1651e-01,\n",
       "         0.0000e+00, 7.5977e-01, 5.3861e-01, 1.3354e-01, 2.7698e-01, 0.0000e+00,\n",
       "         0.0000e+00, 3.3792e-02, 0.0000e+00, 5.8377e-02, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 3.8643e-01, 2.3274e-01, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 2.7508e-02, 2.9558e-01, 0.0000e+00, 0.0000e+00, 6.0465e-02,\n",
       "         0.0000e+00, 1.4296e-02, 0.0000e+00, 1.0059e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3389e-01, 0.0000e+00, 3.5951e-02,\n",
       "         0.0000e+00, 1.7995e-01, 1.3052e-02, 0.0000e+00, 3.5106e-01, 3.7112e-01,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.5873e-03,\n",
       "         3.8225e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.5283e-02, 0.0000e+00,\n",
       "         1.3423e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5896e-01, 2.7026e-01,\n",
       "         8.3034e-01, 0.0000e+00, 3.6902e-01, 0.0000e+00, 8.6107e-01, 0.0000e+00,\n",
       "         3.1288e-01, 0.0000e+00, 0.0000e+00, 2.7667e-02, 1.5446e-01, 7.3399e-01,\n",
       "         0.0000e+00, 1.8710e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.9116e-02,\n",
       "         3.1884e-01, 3.5789e-01, 3.5512e-01, 0.0000e+00, 1.9937e-01, 0.0000e+00,\n",
       "         4.9987e-01, 0.0000e+00, 0.0000e+00, 5.5581e-01, 0.0000e+00, 6.6263e-01,\n",
       "         5.2225e-01, 0.0000e+00, 1.3219e-01, 1.9755e-01, 0.0000e+00, 0.0000e+00,\n",
       "         4.9795e-01, 1.3727e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         4.9031e-01, 5.0195e-01, 4.8707e-01, 4.7500e-01, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 2.5478e-01, 0.0000e+00, 6.8141e-01, 0.0000e+00, 1.9342e-01,\n",
       "         0.0000e+00, 0.0000e+00, 6.4205e-01, 8.0713e-01, 0.0000e+00, 1.8458e-01,\n",
       "         2.0500e-01, 0.0000e+00],\n",
       "        [0.0000e+00, 2.3802e-01, 1.2062e-01, 3.2827e-01, 6.0449e-01, 0.0000e+00,\n",
       "         2.9489e-02, 1.9423e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 6.6714e-01, 1.1677e+00, 0.0000e+00, 3.5785e-01, 0.0000e+00,\n",
       "         5.6718e-01, 0.0000e+00, 2.8760e-01, 2.1079e-01, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0453e-01,\n",
       "         4.9384e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0767e-01, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0140e-01, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.3650e-02, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.1631e-02, 7.1050e-01,\n",
       "         3.2615e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 6.4518e-01, 2.0409e-01, 2.1521e-01,\n",
       "         0.0000e+00, 0.0000e+00, 1.8245e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         1.5035e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 2.7664e-01, 5.6031e-01, 4.1152e-01, 0.0000e+00,\n",
       "         4.9473e-01, 0.0000e+00, 8.8253e-01, 0.0000e+00, 0.0000e+00, 5.0673e-01,\n",
       "         2.9829e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 4.3545e-02, 0.0000e+00, 1.0213e-01, 6.7573e-01, 5.3478e-01,\n",
       "         4.6134e-01, 3.7186e-01, 6.4607e-01, 1.1271e+00, 0.0000e+00, 0.0000e+00,\n",
       "         3.4212e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1803e+00, 0.0000e+00,\n",
       "         3.2929e-02, 0.0000e+00, 4.0945e-01, 0.0000e+00, 0.0000e+00, 2.6843e-02,\n",
       "         3.4669e-01, 2.4447e-01, 1.6930e-01, 0.0000e+00, 5.6047e-01, 0.0000e+00,\n",
       "         2.8491e-01, 5.3231e-01],\n",
       "        [5.2941e-01, 0.0000e+00, 1.0783e-01, 0.0000e+00, 0.0000e+00, 2.8179e-01,\n",
       "         0.0000e+00, 4.3045e-01, 0.0000e+00, 2.0868e-01, 4.1359e-01, 8.2433e-03,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1102e-04, 0.0000e+00,\n",
       "         0.0000e+00, 3.1961e-01, 2.7899e-01, 0.0000e+00, 0.0000e+00, 8.9650e-02,\n",
       "         1.9987e-01, 0.0000e+00, 1.7328e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.6974e-01, 2.5375e-01, 6.8225e-01, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 8.0008e-01, 0.0000e+00, 0.0000e+00, 4.9750e-01,\n",
       "         0.0000e+00, 0.0000e+00, 9.9619e-02, 5.3170e-01, 3.3667e-01, 5.5174e-01,\n",
       "         0.0000e+00, 4.9715e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3558e-01,\n",
       "         7.9514e-01, 0.0000e+00, 0.0000e+00, 3.8183e-01, 1.4453e-01, 0.0000e+00,\n",
       "         4.7477e-01, 1.3818e-01, 7.6935e-01, 0.0000e+00, 0.0000e+00, 1.0041e+00,\n",
       "         2.7787e-01, 0.0000e+00, 7.9694e-01, 0.0000e+00, 8.8212e-01, 0.0000e+00,\n",
       "         7.9148e-02, 1.5136e-01, 0.0000e+00, 4.1625e-01, 7.0012e-01, 1.3297e-01,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.5421e-01, 1.9485e-01, 0.0000e+00,\n",
       "         6.6127e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2321e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 5.6933e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         3.3138e-01, 8.7010e-01, 0.0000e+00, 7.6368e-01, 7.6304e-01, 2.6644e-01,\n",
       "         8.0813e-01, 2.0152e-01, 1.0766e+00, 0.0000e+00, 3.9796e-01, 0.0000e+00,\n",
       "         5.0264e-01, 0.0000e+00, 7.6811e-01, 1.6084e-02, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 4.5490e-01, 0.0000e+00, 0.0000e+00, 1.6086e-01, 8.1044e-01,\n",
       "         0.0000e+00, 0.0000e+00, 8.8829e-01, 4.4534e-01, 0.0000e+00, 2.9558e-01,\n",
       "         8.7141e-01, 4.5317e-02],\n",
       "        [6.8985e-01, 6.4209e-01, 8.1680e-01, 0.0000e+00, 6.5233e-01, 0.0000e+00,\n",
       "         1.8419e-01, 0.0000e+00, 4.8675e-01, 0.0000e+00, 0.0000e+00, 5.2232e-02,\n",
       "         7.1094e-02, 1.6358e-01, 1.0801e+00, 2.6591e-01, 6.4789e-01, 0.0000e+00,\n",
       "         1.1463e+00, 1.3902e-01, 6.3943e-01, 1.6759e-02, 0.0000e+00, 1.6502e-01,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 5.8188e-01, 8.2916e-01, 4.0514e-01,\n",
       "         1.4700e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7862e-01, 1.5588e+00,\n",
       "         0.0000e+00, 9.8852e-01, 0.0000e+00, 1.0545e+00, 7.8672e-02, 0.0000e+00,\n",
       "         8.4921e-01, 0.0000e+00, 7.6028e-01, 3.5861e-02, 4.8688e-01, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6985e-01, 0.0000e+00, 2.1334e-01,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1036e+00, 5.8445e-01, 0.0000e+00,\n",
       "         0.0000e+00, 9.3214e-01, 0.0000e+00, 7.8822e-01, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 8.0414e-01, 0.0000e+00, 0.0000e+00,\n",
       "         8.6735e-01, 0.0000e+00, 0.0000e+00, 3.1902e-01, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 2.8810e-01, 0.0000e+00, 0.0000e+00, 7.4515e-01, 8.3840e-01,\n",
       "         0.0000e+00, 2.9596e-01, 0.0000e+00, 3.2521e-01, 0.0000e+00, 0.0000e+00,\n",
       "         7.0966e-01, 0.0000e+00, 0.0000e+00, 6.6480e-01, 4.6099e-01, 9.8665e-01,\n",
       "         0.0000e+00, 5.2287e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.2623e-01,\n",
       "         0.0000e+00, 5.7640e-01, 8.2497e-01, 5.6289e-01, 0.0000e+00, 0.0000e+00,\n",
       "         8.8282e-02, 0.0000e+00, 0.0000e+00, 4.1320e-01, 2.3215e-01, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 7.1633e-02, 3.3303e-01, 4.7430e-01,\n",
       "         0.0000e+00, 3.1882e-01, 1.7417e+00, 5.4488e-01, 5.9506e-01, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [5.4765e-02, 4.1866e-01, 5.3564e-02, 7.0593e-01, 0.0000e+00, 1.6445e-01,\n",
       "         4.7606e-01, 3.4911e-01, 0.0000e+00, 0.0000e+00, 7.5116e-01, 0.0000e+00,\n",
       "         2.2683e-01, 0.0000e+00, 7.6567e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.5086e-01, 0.0000e+00, 0.0000e+00, 9.4190e-01, 4.3982e-01,\n",
       "         0.0000e+00, 9.4239e-02, 4.0008e-01, 7.9412e-02, 7.9016e-01, 6.5281e-01,\n",
       "         4.7144e-01, 0.0000e+00, 1.4519e-01, 0.0000e+00, 5.3661e-01, 0.0000e+00,\n",
       "         1.2238e-01, 1.3263e-01, 4.8405e-02, 0.0000e+00, 0.0000e+00, 1.2236e+00,\n",
       "         0.0000e+00, 4.9831e-02, 8.5390e-01, 1.0245e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 7.2496e-01, 3.9374e-01, 5.2700e-02, 7.4345e-01, 9.8618e-01,\n",
       "         0.0000e+00, 0.0000e+00, 3.5093e-01, 9.6054e-01, 0.0000e+00, 9.9745e-01,\n",
       "         2.5857e-01, 0.0000e+00, 9.6905e-01, 1.5322e-01, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 6.6744e-01, 7.0132e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         5.5751e-01, 0.0000e+00, 3.7790e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         3.6867e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         2.6445e-01, 0.0000e+00, 4.3572e-02, 0.0000e+00, 9.2815e-01, 0.0000e+00,\n",
       "         3.5176e-01, 0.0000e+00, 2.2397e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         4.9682e-01, 5.6197e-01, 0.0000e+00, 3.7803e-01, 0.0000e+00, 8.1172e-01,\n",
       "         0.0000e+00, 1.5434e+00, 4.9663e-01, 0.0000e+00, 5.5989e-01, 0.0000e+00,\n",
       "         4.3788e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8651e-01, 6.0972e-01,\n",
       "         0.0000e+00, 0.0000e+00, 6.9987e-01, 0.0000e+00, 4.4214e-01, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 3.7861e-01, 0.0000e+00, 1.2192e+00, 1.2271e-01,\n",
       "         1.5545e-01, 0.0000e+00],\n",
       "        [3.7334e-01, 1.2429e-01, 5.0968e-01, 0.0000e+00, 2.9526e-01, 6.5450e-01,\n",
       "         7.2482e-01, 0.0000e+00, 0.0000e+00, 2.8314e-01, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 4.3008e-01, 0.0000e+00, 4.9263e-01, 0.0000e+00,\n",
       "         0.0000e+00, 4.6256e-01, 3.4045e-01, 3.6924e-01, 0.0000e+00, 3.7867e-01,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1144e-01, 0.0000e+00, 1.6336e-01,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.3413e-01, 2.9783e-01,\n",
       "         0.0000e+00, 0.0000e+00, 5.8304e-01, 2.3457e-01, 0.0000e+00, 2.6888e-01,\n",
       "         0.0000e+00, 1.5200e-01, 2.5134e-01, 2.8752e-01, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 2.0154e-02, 1.0135e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.0985e-01, 0.0000e+00, 1.1395e+00, 0.0000e+00, 0.0000e+00,\n",
       "         3.6650e-01, 4.9787e-01, 1.2952e-01, 9.7738e-01, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 8.5836e-01, 0.0000e+00, 0.0000e+00, 1.9869e-01, 0.0000e+00,\n",
       "         9.3509e-01, 1.4697e+00, 0.0000e+00, 1.9902e-01, 4.9883e-02, 1.8191e-01,\n",
       "         0.0000e+00, 0.0000e+00, 2.9197e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.0669e-01, 1.0565e+00,\n",
       "         5.8673e-01, 4.0068e-01, 2.1418e-01, 0.0000e+00, 0.0000e+00, 1.3713e+00,\n",
       "         0.0000e+00, 0.0000e+00, 5.2919e-01, 0.0000e+00, 4.8938e-01, 4.3944e-01,\n",
       "         7.6561e-01, 9.4091e-01, 1.1591e+00, 0.0000e+00, 7.9763e-01, 0.0000e+00,\n",
       "         1.2579e-01, 1.3904e-01, 9.4488e-01, 0.0000e+00, 8.1985e-01, 2.1124e-01,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2612e-01,\n",
       "         5.2759e-01, 1.4859e-01, 0.0000e+00, 0.0000e+00, 1.0190e+00, 0.0000e+00,\n",
       "         4.5254e-01, 0.0000e+00]], device='cuda:0', grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "38f99a33-94f9-4e5a-a956-a3248a5ffef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.4618e-02, -1.3616e-01,  1.0447e-01, -2.2080e-01,  2.5310e-01,\n",
       "         -3.7086e-02,  8.7145e-02, -4.3516e-01,  7.9945e-02,  2.8792e-01,\n",
       "          1.4256e-01,  9.3586e-02, -3.8550e-02,  1.0962e-01, -9.4654e-02,\n",
       "          3.6891e-01,  1.4214e-01,  3.5071e-02,  2.5583e-01,  3.9744e-01,\n",
       "         -6.5413e-02,  6.2235e-02, -2.3154e-01,  1.9187e-01,  5.0682e-01,\n",
       "         -1.0110e-01, -5.3362e-02, -1.0859e-01,  1.8991e-01,  2.3025e-01,\n",
       "         -1.1045e-01,  2.5889e-01, -1.3926e-01,  4.1655e-02,  2.9371e-03,\n",
       "          2.4090e-01,  4.0829e-02, -2.1877e-01, -2.0251e-01,  5.2882e-01,\n",
       "         -2.5396e-02, -2.0216e-01, -2.3425e-01,  1.5301e-01,  2.6718e-01,\n",
       "          2.0572e-01,  2.3076e-03,  8.0562e-02, -4.1910e-02, -1.1471e-01,\n",
       "         -2.6015e-01, -1.4003e-01, -1.5558e-01, -1.6776e-01, -1.6134e-01,\n",
       "         -8.0091e-02,  4.7721e-02, -5.0264e-03,  2.4791e-01, -1.2284e-01,\n",
       "          2.1086e-01,  1.0139e-01, -1.1285e-01,  1.2581e-01, -2.5513e-02,\n",
       "          8.7956e-02,  5.2958e-02,  1.8181e-02, -3.1337e-01, -3.4168e-01,\n",
       "          1.2739e-01,  1.7720e-01,  3.5598e-03, -2.0354e-01, -5.3349e-01,\n",
       "          1.8372e-01,  1.6379e-01,  2.3844e-01, -4.4335e-01],\n",
       "        [-8.0104e-02,  2.0845e-02, -6.6570e-03,  5.9135e-02, -1.2580e-01,\n",
       "         -1.1252e-01, -7.5776e-02, -1.8094e-01, -9.3348e-03,  3.2487e-01,\n",
       "          6.6277e-02, -1.4483e-01, -5.0369e-02,  3.3460e-01, -1.1526e-01,\n",
       "          7.8375e-02, -5.5841e-03,  4.7735e-02,  1.4194e-01,  2.6959e-01,\n",
       "         -3.1074e-01,  3.8322e-01, -1.0213e-01, -1.0509e-01,  2.0671e-01,\n",
       "         -6.3519e-02,  7.5206e-02, -2.8173e-01,  2.1714e-01,  4.7711e-02,\n",
       "         -3.1376e-01,  2.8893e-01,  2.0292e-01, -4.1599e-02, -7.0801e-02,\n",
       "          1.8469e-01, -1.5796e-01, -7.3232e-02,  9.5153e-02,  1.5179e-01,\n",
       "         -5.8596e-03, -6.0084e-04, -1.7386e-01,  2.4956e-01,  1.4016e-01,\n",
       "          1.3824e-01,  8.3279e-02,  2.4141e-01,  4.4543e-01, -8.8865e-02,\n",
       "         -8.0160e-03, -3.0756e-01, -1.4990e-01,  1.4425e-01,  1.8311e-01,\n",
       "          1.2255e-01,  2.4898e-01,  1.2956e-01, -8.5542e-02, -1.5325e-01,\n",
       "          2.2990e-01,  1.6105e-01, -3.6706e-01,  1.3611e-01, -7.1201e-02,\n",
       "         -1.1453e-01,  1.8742e-01,  7.6377e-03, -2.8702e-01, -2.3916e-02,\n",
       "          3.9078e-02,  1.4397e-01,  1.8835e-01, -1.3307e-01, -1.3846e-01,\n",
       "          2.6563e-01,  1.0973e-01, -1.8243e-01, -8.3689e-02],\n",
       "        [-1.4404e-01, -3.9261e-03, -9.2169e-02,  3.3321e-02,  3.2006e-01,\n",
       "         -4.4922e-01,  3.0692e-01, -1.8676e-01, -1.9373e-01,  1.8459e-01,\n",
       "          1.2252e-02, -1.0701e-04,  2.6792e-02,  6.6132e-02, -2.8898e-01,\n",
       "          4.9893e-02,  3.8779e-01, -1.6025e-01, -9.6575e-02, -9.8613e-02,\n",
       "          3.4983e-01, -4.4797e-02, -3.3509e-01,  8.9572e-02,  2.0710e-01,\n",
       "          6.2840e-04, -1.6790e-01, -5.8348e-02,  1.1418e-01, -7.9011e-03,\n",
       "         -9.7580e-03,  2.6561e-02, -4.9980e-03,  1.5220e-01,  4.5852e-02,\n",
       "         -5.8150e-02, -5.9123e-02, -2.8680e-01, -8.9913e-02,  3.7090e-01,\n",
       "         -1.2148e-01,  3.1810e-02, -1.1421e-01,  1.3453e-01,  8.7298e-02,\n",
       "          1.6504e-01, -2.0005e-01,  1.0863e-01, -1.9611e-01, -2.6895e-01,\n",
       "          2.9705e-02, -1.0230e-01, -1.1619e-01,  1.2380e-01,  8.0317e-02,\n",
       "          1.2697e-01,  1.6389e-01, -4.3274e-01, -3.2696e-02, -1.4834e-01,\n",
       "          2.0059e-01,  4.3419e-03,  1.6107e-01,  1.3763e-01,  1.0622e-01,\n",
       "          3.1956e-02,  4.3412e-02, -9.8050e-02, -2.3001e-02, -1.2966e-01,\n",
       "         -2.6517e-01,  3.5520e-02,  4.7626e-02, -3.9441e-02, -2.2130e-01,\n",
       "          3.4089e-01, -2.5664e-01, -1.9704e-01, -6.3956e-02],\n",
       "        [-1.3345e-01, -5.8849e-02, -2.7533e-01, -1.4107e-02,  6.0475e-02,\n",
       "         -4.2625e-01, -2.3332e-02, -3.5895e-01, -1.5166e-01,  4.5009e-01,\n",
       "          1.2353e-01, -1.5322e-01,  2.6886e-02,  1.1692e-01,  3.2626e-02,\n",
       "         -4.7222e-02,  5.3454e-03, -1.1426e-01, -1.3679e-01,  3.3567e-01,\n",
       "         -1.5395e-01,  3.6695e-01, -1.5989e-01, -6.2512e-04,  7.5497e-02,\n",
       "         -2.8341e-01, -3.0874e-02, -2.6786e-01,  2.9992e-01,  2.1392e-01,\n",
       "         -5.4786e-01,  1.5109e-02, -1.1937e-02, -8.6574e-02,  3.4251e-01,\n",
       "          1.6016e-01, -1.7551e-01,  1.9014e-01,  6.3439e-02,  3.9378e-01,\n",
       "          4.9641e-02,  1.0280e-01, -3.8985e-01,  2.0350e-01,  1.0286e-01,\n",
       "          3.5782e-01, -1.8547e-01,  7.6248e-01,  4.9705e-01, -3.9807e-03,\n",
       "          3.5979e-03,  4.8000e-02, -4.1516e-01,  5.2656e-02,  1.4611e-01,\n",
       "          1.5834e-02,  2.2376e-01,  2.6170e-01, -1.5383e-01, -4.4053e-01,\n",
       "          2.4168e-01,  1.2399e-01, -3.5094e-01, -1.3047e-01, -4.8685e-02,\n",
       "         -1.9998e-01,  5.1481e-02, -8.4267e-03, -1.1452e-01, -2.5052e-01,\n",
       "         -4.0223e-01,  2.5120e-01,  2.4911e-01, -3.1948e-01, -4.3370e-01,\n",
       "          3.7906e-02,  9.7059e-02, -2.1602e-01, -1.2777e-01],\n",
       "        [-2.2729e-01,  3.5607e-01,  2.3053e-01, -3.1267e-01, -1.0790e-01,\n",
       "         -3.0664e-01,  3.1993e-01,  5.3050e-02, -4.9286e-01,  4.6528e-01,\n",
       "          2.9562e-01, -2.9737e-01,  3.6927e-02,  1.3207e-01, -4.3753e-01,\n",
       "          7.1240e-03,  3.7561e-01, -5.7029e-01, -1.0733e-01, -1.7762e-01,\n",
       "          3.1571e-01,  1.2363e-01, -5.7959e-02,  1.8571e-01,  8.6700e-02,\n",
       "         -6.3308e-01, -3.0181e-01, -5.0837e-01,  3.1322e-01,  3.0275e-01,\n",
       "         -2.3920e-01,  2.1372e-01,  1.1488e-01,  1.1655e-01,  2.4783e-01,\n",
       "          5.1765e-01,  7.6908e-02, -4.5245e-01, -3.5211e-01,  4.5482e-01,\n",
       "          1.6911e-01, -6.1937e-02,  3.0658e-01,  5.4020e-01,  8.1384e-02,\n",
       "          5.0320e-01,  1.9382e-02,  5.0327e-02,  1.4160e-02, -2.8877e-01,\n",
       "         -1.9211e-01, -2.8981e-01,  2.9624e-02, -2.0544e-01,  2.9227e-01,\n",
       "         -2.5099e-01,  3.8285e-01,  1.1663e-01, -3.1880e-03, -3.1228e-01,\n",
       "          4.0587e-01, -8.0172e-02, -1.0187e-01,  1.2956e-01,  1.6071e-01,\n",
       "          2.0264e-01,  3.3194e-01, -3.7774e-02, -2.7015e-01, -4.8437e-01,\n",
       "          2.4942e-01,  8.6594e-02,  2.6143e-01, -3.0272e-01, -5.4159e-02,\n",
       "          4.4909e-01,  1.2915e-01, -3.2429e-01, -3.3959e-01],\n",
       "        [-2.3581e-02,  2.4398e-01, -2.5489e-01, -8.0422e-02, -1.4197e-02,\n",
       "         -6.2463e-01,  5.6755e-02,  6.4482e-02, -3.7848e-02,  1.5205e-01,\n",
       "         -7.3582e-02, -1.4247e-02, -5.1170e-02, -1.6604e-01,  1.4316e-01,\n",
       "         -3.9195e-01,  1.6030e-01, -5.7442e-01,  1.6888e-01, -1.3029e-01,\n",
       "          1.5143e-01, -1.0598e-01, -1.6872e-01, -7.6739e-03,  2.5130e-01,\n",
       "          1.4699e-01,  7.4961e-02, -2.1914e-01,  5.8670e-01, -7.1274e-02,\n",
       "          9.0029e-02, -1.8743e-01,  1.1929e-01,  5.1829e-02,  2.2789e-01,\n",
       "          4.9360e-01, -2.3241e-01,  2.8629e-01, -2.5058e-01,  3.2473e-01,\n",
       "          1.3867e-01,  2.8046e-01, -1.5224e-01,  1.4823e-01,  3.4398e-01,\n",
       "          1.7562e-01, -2.9447e-01,  3.6920e-01, -1.3005e-01, -4.7166e-02,\n",
       "         -8.9405e-03, -1.5119e-01,  5.0689e-02, -6.1089e-02, -5.2571e-02,\n",
       "          2.6749e-01,  1.1267e-01,  1.0576e-01,  1.1813e-01, -2.2624e-01,\n",
       "          2.4538e-02, -1.7797e-01, -3.8259e-01, -2.4952e-01,  4.2591e-04,\n",
       "          1.5759e-01, -7.9616e-02, -1.7732e-01,  2.3123e-01, -2.0501e-01,\n",
       "         -2.6603e-01,  2.7470e-01,  1.0100e-01, -2.7147e-01, -6.2121e-01,\n",
       "          3.4685e-02, -1.1232e-01,  1.4949e-01, -5.7195e-02],\n",
       "        [ 2.3096e-01,  2.6999e-01, -3.8486e-03, -1.0743e-01, -1.4283e-02,\n",
       "         -5.8341e-01, -1.7840e-02, -2.5008e-01,  1.8041e-02,  5.1522e-01,\n",
       "          1.5470e-01, -7.8391e-02, -1.2832e-01,  3.7530e-01, -2.0171e-01,\n",
       "          3.2375e-01,  5.3994e-02, -1.7228e-01, -1.2675e-01, -3.6460e-02,\n",
       "         -1.3675e-01,  2.1462e-01,  1.0051e-01,  3.5699e-01,  8.5548e-05,\n",
       "         -6.2036e-02, -3.1835e-01, -3.8005e-01,  3.6545e-01,  1.3946e-01,\n",
       "          4.8621e-02,  5.9796e-02,  1.6468e-01, -1.3358e-01,  1.7134e-01,\n",
       "          5.6247e-01, -1.2731e-01, -2.9747e-02, -1.8409e-01,  5.3543e-01,\n",
       "          2.1313e-01, -3.9813e-02,  4.7988e-02, -2.5926e-02, -6.3912e-02,\n",
       "          4.5529e-01,  2.5276e-02,  2.9873e-01,  7.0811e-02, -1.8498e-01,\n",
       "         -5.8136e-01, -2.8955e-01, -1.0586e-01,  2.2990e-02,  1.3407e-02,\n",
       "         -2.0609e-01,  1.1676e-01,  1.4525e-01, -4.8741e-03, -7.2274e-01,\n",
       "          5.0663e-01, -5.1103e-02, -2.2820e-01, -2.5028e-01, -6.9655e-02,\n",
       "         -1.3065e-01,  1.7971e-01, -2.8427e-02,  1.9361e-01, -4.4535e-01,\n",
       "          1.9352e-01, -1.9319e-02, -9.6542e-02, -2.0320e-01, -1.1121e-01,\n",
       "         -7.0027e-02, -1.3311e-01, -3.2352e-01,  3.1228e-02]], device='cuda:0',\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97aa299-b029-47bf-8ba1-7191d60f8f22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
