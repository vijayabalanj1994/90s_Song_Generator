{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3c947b6-ec03-4e21-9bcb-b190fce4b42b",
   "metadata": {},
   "source": [
    "## Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "066ac74b-4996-4f89-8464-23899701be98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe45b09a-f996-4621-bb14-d1d3c4e84ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vijay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\vijay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80ddaf7-db86-4635-8f8c-f921052c7b08",
   "metadata": {},
   "source": [
    "#### Checking if CUDA is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70856f36-e66e-4883-8715-c777f6cc4c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec3b6f9-ed2f-4091-8eaa-70b35a8e9258",
   "metadata": {},
   "source": [
    "## Example Song (Input - Document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "986ea77f-da7e-4c48-9bf1-77d4cf5a54f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "song= \"\"\"We are no strangers to love\n",
    "You know the rules and so do I\n",
    "A full commitments what Im thinking of\n",
    "You wouldnt get this from any other guy\n",
    "I just wanna tell you how Im feeling\n",
    "Gotta make you understand\n",
    "Never gonna give you up\n",
    "Never gonna let you down\n",
    "Never gonna run around and desert you\n",
    "Never gonna make you cry\n",
    "Never gonna say goodbye\n",
    "Never gonna tell a lie and hurt you\n",
    "Weve known each other for so long\n",
    "Your hearts been aching but youre too shy to say it\n",
    "Inside we both know whats been going on\n",
    "We know the game and were gonna play it\n",
    "And if you ask me how Im feeling\n",
    "Dont tell me youre too blind to see\n",
    "Never gonna give you up\n",
    "Never gonna let you down\n",
    "Never gonna run around and desert you\n",
    "Never gonna make you cry\n",
    "Never gonna say goodbye\n",
    "Never gonna tell a lie and hurt you\n",
    "Never gonna give you up\n",
    "Never gonna let you down\n",
    "Never gonna run around and desert you\n",
    "Never gonna make you cry\n",
    "Never gonna say goodbye\n",
    "Never gonna tell a lie and hurt you\n",
    "Weve known each other for so long\n",
    "Your hearts been aching but youre too shy to say it\n",
    "Inside we both know whats been going on\n",
    "We know the game and were gonna play it\n",
    "I just wanna tell you how Im feeling\n",
    "Gotta make you understand\n",
    "Never gonna give you up\n",
    "Never gonna let you down\n",
    "Never gonna run around and desert you\n",
    "Never gonna make you cry\n",
    "Never gonna say goodbye\n",
    "Never gonna tell a lie and hurt you\n",
    "Never gonna give you up\n",
    "Never gonna let you down\n",
    "Never gonna run around and desert you\n",
    "Never gonna make you cry\n",
    "Never gonna say goodbye\n",
    "Never gonna tell a lie and hurt you\n",
    "Never gonna give you up\n",
    "Never gonna let you down\n",
    "Never gonna run around and desert you\n",
    "Never gonna make you cry\n",
    "Never gonna say goodbye\n",
    "Never gonna tell a lie and hurt you\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb0f80c-3046-476f-a74f-7832dae685a9",
   "metadata": {},
   "source": [
    "## Bigram language model - Using Conditional Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c5c573-fb85-407c-89a3-194ca26ac20a",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08bed078-43d6-4f29-9344-110ccc27e4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Input Word:- 'Word2Vec'\n",
      "Example Output Word:- WordVec\n"
     ]
    }
   ],
   "source": [
    "# a function to remove all not-word characters in a word\n",
    "def preprocess_string(s):\n",
    "    # remove all non-word charecters except numbers and letters\n",
    "    s = re.sub(r\"[^\\w\\s]\",'',s)\n",
    "    # replace all runs of witespaces with no space\n",
    "    s = re.sub(r\"\\s+\",'',s)\n",
    "    # replace digits with no space\n",
    "    s = re.sub(r\"\\d\",'',s)\n",
    "    return s\n",
    "\n",
    "print(f\"Example Input Word:- 'Word2Vec'\\nExample Output Word:- {preprocess_string('Word2Vec')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "815342b6-8f1e-4a46-bb56-8edbb248870d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1st ten tokens:-\n",
      "['we', 'are', 'no', 'strangers', 'to', 'love', 'you', 'know', 'the', 'rules']\n",
      "Total no of tokens :-385\n",
      "Total no of unique tokens :-80\n"
     ]
    }
   ],
   "source": [
    "# using the \"word_tokenize\" function from \"nltk\" library for tokenization\n",
    "def preprocess(words):\n",
    "    tokens = word_tokenize(words)\n",
    "    tokens = [preprocess_string(w) for w in tokens]\n",
    "    return [w.lower() for w in tokens if len(w) != 0 or not(w in string.punctuation)]\n",
    "\n",
    "tokens=preprocess(song) # preserves the order\n",
    "vocabulary = set(tokens)\n",
    "print(f\"Example 1st ten tokens:-\\n{tokens[0:10]}\")\n",
    "print(f'Total no of tokens :-{len(tokens)}')\n",
    "print(f'Total no of unique tokens :-{len(vocabulary)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aac3553-2339-4acc-8ba5-0bd872f8b423",
   "metadata": {},
   "source": [
    "#### Calcualting the frequency distribution of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaa7e3dd-2377-47e0-a6f1-bbbbe811d4de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'na': 40, 'gon': 38, 'you': 37, 'never': 36, 'and': 16, 'tell': 9, 'make': 8, 'say': 8, 'a': 7, 'give': 6, ...})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total word count:- 385\n",
      "Total unique word count:- 80 \n"
     ]
    }
   ],
   "source": [
    "# using the \"FreqDist\" function from \"nltk\" library to calculate the token frequecy\n",
    "fdist = nltk.FreqDist(tokens)\n",
    "display(fdist)\n",
    "\n",
    "# total counts\n",
    "print(f\"Total word count:- {sum(fdist.values())}\")\n",
    "print(f\"Total unique word count:- {len(list(fdist.keys()))} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "875f68ed-79c3-4372-b965-84ca6cb6652e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# a bar plot with the first ten token frequencies using the \"pyplot\" function from \"matplotlib\" library\n",
    "plt.bar(list(fdist.keys())[0:10], list(fdist.values())[0:10])\n",
    "plt.xlabel(\"Words\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec57d961-1126-481d-a477-84ba5a1f117a",
   "metadata": {},
   "source": [
    "#### Creating bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8628a95b-2b25-41dc-bbdd-a1e68e138929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first ten bigrmas:-\n",
      "[('we', 'are'), ('are', 'no'), ('no', 'strangers'), ('strangers', 'to'), ('to', 'love'), ('love', 'you'), ('you', 'know'), ('know', 'the'), ('the', 'rules'), ('rules', 'and')]\n"
     ]
    }
   ],
   "source": [
    "# creating consecutive pairs of tokens using the \"bigrams\" function from \"nltk\" library\n",
    "bigrams = list(nltk.bigrams(tokens))\n",
    "print(f'The first ten bigrmas:-\\n{bigrams[:10]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00943c82-1843-4fb6-a554-935ae93da3c9",
   "metadata": {},
   "source": [
    "#### Calcutating the frequency distribution of bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96970538-e5ba-43e9-ad57-943c15763a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({('gon', 'na'): 38, ('never', 'gon'): 36, ('you', 'never'): 9, ('na', 'tell'): 8, ('make', 'you'): 8, ('na', 'give'): 6, ('give', 'you'): 6, ('you', 'up'): 6, ('up', 'never'): 6, ('na', 'let'): 6, ...})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total bigram count:- 384\n",
      "Total unique bigram count:- 119 \n"
     ]
    }
   ],
   "source": [
    "# using the \"FreqDist\" function from \"nltk\" library to calculate the bigram frequecy\n",
    "freq_bigrams = nltk.FreqDist(nltk.bigrams(tokens))\n",
    "display(freq_bigrams)\n",
    "\n",
    "# total counts\n",
    "print(f\"Total bigram count:- {sum(freq_bigrams.values())}\")\n",
    "print(f\"Total unique bigram count:- {len(list(freq_bigrams.keys()))} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cd8f4b-b8a8-4990-99b5-7d97a3cd746d",
   "metadata": {},
   "source": [
    "#### Calculating the conditional probabilities for the example token - \"strangers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7774f6ad-9b6b-4df4-a60a-0c7956a454d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 4 more likely word to occur after 'strangers':-\n",
      " [('to', 1.0), ('commitments', 0.0), ('desert', 0.0), ('me', 0.0)]\n"
     ]
    }
   ],
   "source": [
    "word = 'strangers'\n",
    "vocab_probabilities = {}\n",
    "for next_word in vocabulary:\n",
    "    vocab_probabilities[next_word] = freq_bigrams[(word, next_word)]/fdist[word]\n",
    "\n",
    "vocab_probabilities = sorted(vocab_probabilities.items(), key=lambda x:x[1], reverse=True)\n",
    "\n",
    "print(\"Top 4 more likely word to occur after 'strangers':-\\n\", vocab_probabilities[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859290ca-8942-4119-bcf7-0d9cc0c0c5dd",
   "metadata": {},
   "source": [
    "#### A function for next word prediction using conditional probability of the next word given a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9a5932d-28cc-422d-9b0a-85501fad6f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 4 more likely word to occur after 'strangers':-\n",
      " [('to', 1.0), ('commitments', 0.0), ('desert', 0.0), ('me', 0.0)]\n"
     ]
    }
   ],
   "source": [
    "def make_predictions(input_context_words, freq_grams, norm,vocabulary=vocabulary):\n",
    "    vocab_probabilities = {}\n",
    "    input_context_tokens = preprocess(input_context_words)\n",
    "\n",
    "    # calculating the probabilities\n",
    "    for next_word in vocabulary:\n",
    "        temp = input_context_tokens.copy()\n",
    "        temp.append(next_word) # adding the next word to the context\n",
    "\n",
    "        #calculating the conditional probability\n",
    "        vocab_probabilities[next_word] = freq_grams[tuple(temp)] / norm\n",
    "\n",
    "    # sorting the probabilities\n",
    "    vocab_probabilities = sorted(vocab_probabilities.items(), key=lambda x:x[1], reverse=True)\n",
    "\n",
    "    return vocab_probabilities\n",
    "\n",
    "print(\"Top 4 more likely word to occur after 'strangers':-\\n\", make_predictions('strangers', freq_bigrams, fdist['strangers'])[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f558c21b-beb2-4597-85e7-e91fe5cb193e",
   "metadata": {},
   "source": [
    "#### Generating a song using the bigram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d928ebd-5e06-4e16-be4d-58329f064c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we know the game and desert you never gon na tell a lie and desert you never gon na tell a lie and desert you never gon na tell a lie and desert you never gon na tell a lie and desert you never gon na tell a lie and desert you never gon na tell a lie and desert you never gon na tell a lie and desert you never gon na tell a lie and desert you never gon na tell a lie and desert you never gon na tell a lie and desert you never gon na tell\n"
     ]
    }
   ],
   "source": [
    "my_song=\"we\"\n",
    "input_word = my_song\n",
    "for i in range(100):\n",
    "    next_word = make_predictions(input_word, freq_bigrams, fdist[input_word])[0][0]\n",
    "    my_song += \" \"+ next_word\n",
    "    input_word = next_word\n",
    "\n",
    "print(my_song)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1a0820-8e96-49db-9674-dab4d997ae8a",
   "metadata": {},
   "source": [
    "## Language Models - Using Feedforward Neural Networks (FNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40791081-9b30-493d-ae56-704873c0c5c8",
   "metadata": {},
   "source": [
    "#### Tokenization and building the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37c6eb42-556e-46e1-9737-c87fd6740d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of tokens in the song:-  343\n",
      "Vocab Size:- 79\n",
      "\n",
      "First 10 word of the song:-\n",
      " We are no strangers to love You know the rules \n",
      "\n",
      "Tokenized text:-\n",
      " ['we', 'are', 'no', 'strangers', 'to', 'love', 'you', 'know', 'the', 'rules'] \n",
      "\n",
      "Token indices:-\n",
      " [21, 58, 70, 74, 25, 69, 2, 20, 31, 72]\n"
     ]
    }
   ],
   "source": [
    "# using the \"get_tokenizer\" function from \"torchtext\" library for tokenization\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "tokens = tokenizer(song)\n",
    "print('No of tokens in the song:- ',len(tokens))\n",
    "\n",
    "# an iterable to generate the vocabulary\n",
    "tokenized_song = map(tokenizer, song.split())\n",
    "\n",
    "# using the 'buid_vocab_from_iterator' function from 'torchtext' library\n",
    "vocab = build_vocab_from_iterator(tokenized_song, specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab['<unk>']) # # This index will be returned when OOV token is queried\n",
    "vocab_size = len(vocab)\n",
    "print(f\"Vocab Size:- {vocab_size}\\n\")\n",
    "\n",
    "# printing the tokenized text and token indices of 1st 10 words of the song\n",
    "song_first_10 = \" \".join(song.split()[:10])\n",
    "tokenized_text = tokenizer(song_first_10)\n",
    "token_indices = vocab(tokenized_text)\n",
    "print(\"First 10 word of the song:-\\n\",song_first_10,\"\\n\")\n",
    "print(\"Tokenized text:-\\n\",tokenized_text,\"\\n\")\n",
    "print(\"Token indices:-\\n\", token_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805c2d9c-8ea6-4b59-a34b-477c12e748e2",
   "metadata": {},
   "source": [
    "#### Creating n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "529196d4-b629-4510-94bc-240146004153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([context words list], target-word)\n",
      "\n",
      "([t-1,t-2,t-3]) t\n",
      "\n",
      "(['no', 'are', 'we'], 'strangers')\n",
      "(['strangers', 'no', 'are'], 'to')\n",
      "(['to', 'strangers', 'no'], 'love')\n",
      "(['love', 'to', 'strangers'], 'you')\n",
      "(['you', 'love', 'to'], 'know')\n"
     ]
    }
   ],
   "source": [
    "CONTEXT_SIZE = 3\n",
    "ngrams = [\n",
    "    ([tokens[i-j-1] for j in range(CONTEXT_SIZE)], tokens[i])\n",
    "    for i in range(CONTEXT_SIZE, len(tokens))\n",
    "]\n",
    "\n",
    "# printing the first 5 ngram\n",
    "print(\"([context words list], target-word)\\n\")\n",
    "print(\"([t-1,t-2,t-3]) t\\n\")\n",
    "for ngram in ngrams[:5]: print(ngram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133b8043-dd5c-448b-87c0-c143445afc83",
   "metadata": {},
   "source": [
    "#### Pre-processing pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dde21cd-a9c1-44ba-8fff-e1059d44fdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipline to convert raw text into token indices using the \"tokenizer\" and \"vocab\" functions defined about\n",
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "\n",
    "# a pipline to get token given token index\n",
    "index_to_token_pipeline = lambda x: vocab.get_itos()[x]\n",
    "\n",
    "\n",
    "CONTEXT_SIZE=3\n",
    "BATCH_SIZE=10\n",
    "EMBEDDING_DIM = 10\n",
    "\n",
    "# the collate function to process the batches from the dataloaders\n",
    "def collate_batch(batch):\n",
    "    batch_size = len(batch)\n",
    "    context, target = [], []\n",
    "    for i in range(CONTEXT_SIZE, batch_size):\n",
    "        target.append(vocab([batch[i]]))\n",
    "        context.append(vocab([batch[i-j-1] for j in range(CONTEXT_SIZE)]))\n",
    "    return torch.tensor(context).to(device), torch.tensor(target).to(device).reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f8c4c4-16a8-406a-a1d2-3be387bd9b87",
   "metadata": {},
   "source": [
    "#### Creating dataloaders for ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "310b5ea4-e1fa-4b0d-b9af-d5bb21cd6777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data in the first batch:- \n",
      "\n",
      "Contect Words:- [no, are, we]             Target Word:- strangers\n",
      "Contect Words:- [strangers, no, are]      Target Word:- to\n",
      "Contect Words:- [to, strangers, no]       Target Word:- love\n",
      "Contect Words:- [love, to, strangers]     Target Word:- you\n",
      "Contect Words:- [you, love, to]           Target Word:- know\n",
      "Contect Words:- [know, you, love]         Target Word:- the\n",
      "Contect Words:- [the, know, you]          Target Word:- rules\n",
      "\n",
      "Context tensors:- \n",
      " tensor([[70, 58, 21],\n",
      "        [74, 70, 58],\n",
      "        [25, 74, 70],\n",
      "        [69, 25, 74],\n",
      "        [ 2, 69, 25],\n",
      "        [20,  2, 69],\n",
      "        [31, 20,  2]], device='cuda:0')\n",
      "\n",
      "Target tensor:- \n",
      " tensor([74, 25, 69,  2, 20, 31, 72], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 10\n",
    "padding = BATCH_SIZE - len(tokens)%BATCH_SIZE # appending the beginning of the song to the end to get unifrom batches\n",
    "tokens_paded = tokens + tokens[:padding]\n",
    "\n",
    "# creating dataloaders using \"DataLoader\" function from \"pytorch\" library\n",
    "dataloader = DataLoader(\n",
    "    tokens_paded,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_batch\n",
    ")\n",
    "\n",
    "#printing the data in the first batch\n",
    "print(\"The data in the first batch:- \\n\")\n",
    "context_tensors, target_tensors = next(iter(dataloader))\n",
    "for context_tensor, target_tensor in zip(context_tensors, target_tensors):\n",
    "    context_words = [index_to_token_pipeline(t) for t in context_tensor]\n",
    "    target_word = index_to_token_pipeline(target_tensor)\n",
    "    print(\"Contect Words:- {:<25} Target Word:- {}\".format(\"[\"+\", \".join(context_words)+\"]\", target_word))\n",
    "print(\"\\nContext tensors:- \\n\", context_tensors)\n",
    "print(\"\\nTarget tensor:- \\n\", target_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f3a829-d1e4-4eaa-8d2c-f41ea2181dd2",
   "metadata": {},
   "source": [
    "#### Defining the Nural Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10c75c5b-d165-4cd2-bf89-f83b1992cc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a feed forward NN implemented using \"nn.Embedding\", \"nn.Linear\" and \"nn.functional\" functions from \"pytorch\" library\n",
    "\n",
    "class NGramLanguageModeler(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        self.context_size = context_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size*embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs) \n",
    "        embeds = torch.reshape(embeds, (-1, self.context_size*self.embedding_dim))\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68827b98-7707-4f08-9b1b-6cf044e42e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating the model\n",
    "EMBEDDING_DIM = 10\n",
    "model = NGramLanguageModeler(vocab_size, EMBEDDING_DIM, CONTEXT_SIZE).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ca527c-6489-4bea-b43d-c2507a2beef2",
   "metadata": {},
   "source": [
    "#### Example of one forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e04ebea-40bb-4bfa-865c-8e0590bc9f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example forward pass of the first n_gram:\n",
      "\n",
      "Contect Words:- [no, are, we]             Target Word:- strangers\n",
      "\n",
      "Context tensors:- tensor([[70, 58, 21], device='cuda:0')\n",
      "\n",
      "\n",
      "Target tensor:- tensor(74, device='cuda:0')\n",
      "\n",
      "Context tensor embeddings:-\n",
      " tensor([[-0.8870,  2.3939, -1.1147, -1.9372, -0.2663, -0.0455,  1.6170, -2.8516,\n",
      "          1.7747, -0.6646],\n",
      "        [ 0.5231,  0.5068, -0.3782,  1.1446, -1.3129,  1.7024,  0.3980,  0.1831,\n",
      "          0.6623,  1.8832],\n",
      "        [-0.3081, -1.1628, -0.1496, -0.6746, -0.2522,  1.1502, -0.7187, -1.5033,\n",
      "         -2.6277, -1.2195]], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "Re-shaped Context tensor embeddings:-\n",
      " tensor([-0.8870,  2.3939, -1.1147, -1.9372, -0.2663, -0.0455,  1.6170, -2.8516,\n",
      "         1.7747, -0.6646,  0.5231,  0.5068, -0.3782,  1.1446, -1.3129,  1.7024,\n",
      "         0.3980,  0.1831,  0.6623,  1.8832, -0.3081, -1.1628, -0.1496, -0.6746,\n",
      "        -0.2522,  1.1502, -0.7187, -1.5033, -2.6277, -1.2195], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "\n",
      "Hidden layer output:-\n",
      " tensor([0.0000, 0.1649, 2.2831, 1.2413, 0.6371, 0.0000, 0.0000, 0.4038, 0.0000,\n",
      "        0.2693, 0.1653, 0.8868, 0.0000, 0.0000, 0.0000, 0.5888, 0.0000, 0.9767,\n",
      "        0.3255, 0.0000, 0.7022, 0.8762, 0.0000, 0.0000, 0.1881, 0.4828, 0.0000,\n",
      "        1.2983, 1.0612, 0.4302, 0.3728, 0.0000, 0.0000, 0.5931, 0.1138, 0.5366,\n",
      "        0.0038, 0.3705, 0.8677, 0.0000, 0.1289, 0.6014, 0.0756, 0.8895, 1.3648,\n",
      "        1.9916, 0.5834, 0.1231, 0.3004, 0.0000, 0.0000, 0.0000, 0.8877, 0.0000,\n",
      "        0.4953, 0.0000, 0.0000, 0.9868, 0.0000, 0.0809, 0.0000, 0.6625, 0.5320,\n",
      "        1.0148, 1.2516, 0.0000, 0.5014, 0.0000, 0.6212, 0.5451, 0.5720, 0.0130,\n",
      "        0.4407, 0.0000, 1.6076, 0.6775, 1.1111, 0.0000, 0.0000, 0.0000, 0.8222,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.6490, 0.0000, 0.0000, 0.0000, 1.1346,\n",
      "        0.0000, 1.3021, 0.5890, 0.5326, 0.0143, 0.0825, 1.0690, 0.0000, 0.0000,\n",
      "        0.0000, 0.3149, 0.0000, 0.0000, 0.6487, 0.2180, 0.2793, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.5290, 1.2925, 0.0000, 0.0000, 1.0437,\n",
      "        0.0000, 0.8255, 0.0000, 0.0000, 0.1075, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.3513, 0.0000], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "\n",
      "Nural Network otuput:-\n",
      " tensor([ 3.1901e-01, -1.3999e-01,  2.7247e-01,  1.3569e-01, -6.9481e-01,\n",
      "        -3.5133e-01,  2.8594e-01,  3.6050e-01,  1.7339e-01,  7.8033e-02,\n",
      "         4.8643e-02,  4.7001e-02,  1.3364e-01,  1.7039e-01, -9.6724e-02,\n",
      "        -2.1358e-01, -8.1034e-02, -3.4032e-01, -9.7140e-02, -1.0614e-01,\n",
      "        -4.0499e-01, -2.6336e-01,  2.6009e-01,  3.4052e-01,  1.5313e-01,\n",
      "        -1.6889e-01,  7.8035e-02, -2.7420e-01, -5.0900e-04, -3.1157e-01,\n",
      "         8.9456e-02, -5.7447e-02,  1.8061e-01,  8.1998e-01, -5.8344e-01,\n",
      "        -4.4822e-01,  6.3564e-02,  2.1373e-01,  1.9934e-01, -1.5031e-01,\n",
      "        -1.0745e-01, -3.1693e-01,  2.1644e-01,  1.7905e-01,  3.2805e-01,\n",
      "         1.8601e-01,  4.8829e-01, -1.6550e-01, -1.3437e-01, -4.4874e-01,\n",
      "         1.7383e-01,  5.3512e-01,  8.1903e-01,  1.9788e-01,  2.6242e-01,\n",
      "        -3.2825e-01, -4.0854e-03,  4.3868e-01, -1.1425e-01,  4.7125e-01,\n",
      "        -9.1686e-02,  6.7779e-01,  4.9226e-01, -1.4490e-01, -3.5199e-01,\n",
      "         2.2522e-01, -8.0353e-02,  2.0035e-01, -6.5715e-01,  7.3297e-02,\n",
      "         5.7121e-01, -5.8250e-01,  5.5349e-01, -5.3406e-01, -4.3839e-01,\n",
      "        -1.9793e-01, -2.4787e-02, -2.4367e-01, -2.6368e-02], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "\n",
      "Models prediction:-  tensor(33, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# getting the embeddings of the context_tensors\n",
    "embedded_context_tensor = model.embeddings(context_tensors)\n",
    "# reshaping the context tensors to (EMBEDDING_DIM * CONTEXT_SIZE) dimention\n",
    "embedded_context_tensor_reshaped = torch.reshape(embedded_context_tensor, (-1,EMBEDDING_DIM * CONTEXT_SIZE))\n",
    "# passing through the first linear layer and relu activation function\n",
    "hidden_out = F.relu(model.linear1(embedded_context_tensor_reshaped))\n",
    "# final layer output\n",
    "nn_out = model.linear2(hidden_out)\n",
    "\n",
    "print(\"Example forward pass of the first n_gram:\\n\")\n",
    "print(\"Contect Words:- [no, are, we]             Target Word:- strangers\\n\")\n",
    "print(\"Context tensors:- tensor([[70, 58, 21], device='cuda:0')\\n\")\n",
    "print(\"\\nTarget tensor:- tensor(74, device='cuda:0')\\n\")\n",
    "print(\"Context tensor embeddings:-\\n\",embedded_context_tensor[0])\n",
    "print(\"\\nRe-shaped Context tensor embeddings:-\\n\", embedded_context_tensor_reshaped[0])\n",
    "print(\"\\nHidden layer output:-\\n\", hidden_out[0])\n",
    "print(\"\\nNural Network otuput:-\\n\", nn_out[0])\n",
    "print(\"\\nModels prediction:- \",torch.argmax(nn_out[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b815f7-d9f5-4e13-8cf5-3cff563f90e7",
   "metadata": {},
   "source": [
    "#### Training the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb29c1e7-9b55-4aa6-8f53-320f95181c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, number_of_epoches=100):\n",
    "\n",
    "    # defining the learning rate, loss criterion, optimizer and learning rate scheduler using functions from the PyTorch Library \n",
    "    LR = 0.01 # learning rate\n",
    "    criterion = torch.nn.CrossEntropyLoss() # loss criterion \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=LR) # optimizer \n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1.0, gamma=0.1) #learning rate scheduler\n",
    "    \n",
    "    EPOCHES_LOSS = []\n",
    "\n",
    "    for epoch in tqdm(range(number_of_epoches)):\n",
    "        \n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for context_tensors, target_tensors in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            predicted = model(context_tensors)\n",
    "            loss = criterion(predicted, target_tensors.reshape(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        EPOCHES_LOSS.append(total_loss/len(dataloader))\n",
    "\n",
    "    return EPOCHES_LOSS            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19b6c15e-141f-45e1-82b6-eb651dd16192",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 25.81it/s]\n"
     ]
    }
   ],
   "source": [
    "CONTEXT_SIZE = 2\n",
    "model_2_gram = NGramLanguageModeler(vocab_size, EMBEDDING_DIM, CONTEXT_SIZE).to(device)\n",
    "loss_2_gram = train(dataloader,model_2_gram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38a18b8-1d29-43bd-aba0-1351f525440b",
   "metadata": {},
   "source": [
    "#### A function to generate songs using the n-gram NN based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6fa582e-2238-4b7e-98b0-14837056b123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are no strangers to love you cry never gonna tell a lie and hurt you never gonna tell a lie and hurt you never gonna tell a lie and hurt you never gonna tell a lie and hurt you never gonna tell a lie and hurt you never gonna tell a lie and hurt you never gonna tell a lie and hurt you never gonna tell a lie and hurt you never gonna tell a lie and hurt you never gonna tell a lie and hurt you never gonna tell a lie and hurt you never gonna tell a lie and\n"
     ]
    }
   ],
   "source": [
    "def write_song(model, number_of_words=100, n_gram=2):\n",
    "    my_song = \" \".join(song.split()[:n_gram])\n",
    "    for i in range(number_of_words):\n",
    "        with torch.no_grad():\n",
    "            context_word_indexes = torch.tensor(text_pipeline(\" \".join(my_song.split()[-1*n_gram:][::-1]))).to(device)  \n",
    "            next_word = index_to_token_pipeline(torch.argmax(model(context_word_indexes)))\n",
    "            my_song += \" \"+next_word\n",
    "    return my_song\n",
    "\n",
    "print(write_song(model_2_gram, number_of_words=100, n_gram=CONTEXT_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7415a7d5-0ebf-4a57-b838-4c67bcc07702",
   "metadata": {},
   "source": [
    "#### Visualizing Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4348b23-0f99-4e2d-95d7-a9e16f720ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"C:\\Users\\vijay\\anaconda3\\envs\\IBM_CUDA\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "  File \"C:\\Users\\vijay\\anaconda3\\envs\\IBM_CUDA\\lib\\subprocess.py\", line 505, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "  File \"C:\\Users\\vijay\\anaconda3\\envs\\IBM_CUDA\\lib\\subprocess.py\", line 951, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Users\\vijay\\anaconda3\\envs\\IBM_CUDA\\lib\\subprocess.py\", line 1436, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n"
     ]
    }
   ],
   "source": [
    "# extracting the embeddings from the trained model\n",
    "X = model_2_gram.embeddings.weight.cpu().detach().numpy()\n",
    "\n",
    "# performing t-SNE on the embeddings to reduce their dimentionality to 2D using \"TSNE\" function from \"sklearn\" libary\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_2d = tsne.fit_transform(X)\n",
    "\n",
    "labels = []\n",
    "\n",
    "# annotadating the first 20 words\n",
    "for j in range(len(X_2d)):\n",
    "    if j<20:\n",
    "        plt.scatter(X_2d[j,0], X_2d[j,1], label=index_to_token_pipeline(j))\n",
    "        labels.append(index_to_token_pipeline(j))\n",
    "        plt.annotate(index_to_token_pipeline(j),\n",
    "                    (X_2d[j,0], X_2d[j,1]),\n",
    "                    textcoords=\"offset points\",\n",
    "                    xytext=(0,10),\n",
    "                    ha='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21128264-4d82-429b-b5ec-b787141c3874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08868341, -2.4159017 ],\n",
       "       [-0.4374752 ,  0.61073565],\n",
       "       [-0.5305739 ,  0.79303926],\n",
       "       [-1.616542  ,  2.870261  ],\n",
       "       [ 2.578322  , -0.41275975],\n",
       "       [ 0.28545597, -3.7509255 ],\n",
       "       [ 2.8953693 , -1.1081582 ],\n",
       "       [-1.0609326 , -2.6865761 ],\n",
       "       [ 0.97101223, -3.5547671 ],\n",
       "       [-2.3084466 ,  2.397595  ],\n",
       "       [-1.545617  ,  1.3616784 ],\n",
       "       [-1.7343966 ,  1.4974923 ],\n",
       "       [-2.0451756 , -1.1454563 ],\n",
       "       [-3.629665  , -1.3764904 ],\n",
       "       [ 1.3931386 ,  0.7359126 ],\n",
       "       [ 3.0489042 ,  0.03139213],\n",
       "       [ 4.106683  , -1.593044  ],\n",
       "       [-1.2047275 , -4.6147804 ],\n",
       "       [-0.0934489 ,  2.0409873 ],\n",
       "       [-1.2260092 , -1.148512  ],\n",
       "       [-2.063818  ,  0.3724741 ],\n",
       "       [-2.0620568 , -3.581873  ],\n",
       "       [ 3.9015174 , -1.0395881 ],\n",
       "       [ 0.15487722, -0.57492477],\n",
       "       [-3.315103  , -1.3455572 ],\n",
       "       [-3.2994807 ,  0.8725821 ],\n",
       "       [-0.9895904 , -0.5230278 ],\n",
       "       [-0.70551085,  0.621138  ],\n",
       "       [-1.3639581 ,  0.47225296],\n",
       "       [-0.06953584,  1.5422959 ],\n",
       "       [-2.291211  , -1.6164187 ],\n",
       "       [-2.373677  , -2.515129  ],\n",
       "       [-2.9952457 , -2.1403763 ],\n",
       "       [-0.04469188, -0.73917556],\n",
       "       [-0.7437308 ,  1.4293598 ],\n",
       "       [ 1.8734405 , -1.7342882 ],\n",
       "       [-1.3763332 , -2.8786683 ],\n",
       "       [-3.0958564 , -0.00996873],\n",
       "       [-2.9049175 , -2.5533645 ],\n",
       "       [-0.10713759, -2.3068783 ],\n",
       "       [ 1.5530653 ,  0.83297265],\n",
       "       [-1.4845667 , -0.53467786],\n",
       "       [ 1.3153944 , -1.7574109 ],\n",
       "       [-0.5811203 , -0.75679946],\n",
       "       [ 1.54757   , -0.5167202 ],\n",
       "       [-0.2768519 , -3.1283188 ],\n",
       "       [ 1.8749346 , -1.9988954 ],\n",
       "       [ 0.29693794, -1.4742656 ],\n",
       "       [-3.0542974 , -3.856827  ],\n",
       "       [ 1.8782055 , -2.9763606 ],\n",
       "       [ 2.0305989 ,  2.0471966 ],\n",
       "       [ 0.11570095,  2.2869332 ],\n",
       "       [-1.5405469 , -1.1351593 ],\n",
       "       [ 1.556188  , -0.54707676],\n",
       "       [ 0.1906028 , -0.74753356],\n",
       "       [ 0.6333427 , -2.1273074 ],\n",
       "       [-2.6845932 , -0.04106977],\n",
       "       [ 0.95979327, -2.6022184 ],\n",
       "       [-0.50526386, -2.278906  ],\n",
       "       [-0.12555155, -3.2102966 ],\n",
       "       [ 2.3454814 ,  0.2101748 ],\n",
       "       [ 1.3814272 ,  0.29925138],\n",
       "       [-2.7687204 , -0.08878162],\n",
       "       [-2.0556588 , -1.0152267 ],\n",
       "       [ 1.5519354 , -0.88987917],\n",
       "       [ 2.5257666 , -2.5198874 ],\n",
       "       [ 0.01858285, -2.1295068 ],\n",
       "       [ 2.4088492 ,  0.25490925],\n",
       "       [ 0.3344754 , -4.190084  ],\n",
       "       [ 3.4628744 , -0.74211663],\n",
       "       [-0.8647465 , -3.9176161 ],\n",
       "       [ 0.4733854 ,  0.33713952],\n",
       "       [-2.4516494 , -3.8047357 ],\n",
       "       [-0.0643357 , -3.3067396 ],\n",
       "       [ 3.7120953 ,  0.7144056 ],\n",
       "       [ 0.88459533,  1.8994181 ],\n",
       "       [ 2.450702  ,  1.0135646 ],\n",
       "       [-0.08657802,  0.7207278 ],\n",
       "       [-1.2360708 , -2.4643517 ]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1c0aa8-ddbb-4bc4-9363-dac04198fc18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
